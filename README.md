# Arvato's Costumer Segmentation Report

This repository contains code and associated files for Arvato's Customer Segmentation Report using AWS SageMaker, as part of Udacity Machine Learning Nanodegree Capstone Project.


## Table of Contents
- [Project Overview](#projectoverview)
- [Project Structure](#projectstructure)
- [Setup Instructions](#setup)
- [Dataset](#dataset)
- [Results](#results)
- [References](#references)
- [Acknowledges](#acknowledges)

***
<a id='projectoverview'></a>

## Project Overview
This projects is comprised of three main tasks: 
 - Preparing data and performing Exploratory data analysis
 - Generating a Customer Segmentation report based on demographic information of general population using unsupervised methods (PCA + k-Means)
 - Binary classification of people responding to mail order campaign based on demographic and mailout response information, using supervised methods (such as Neural Networks and XGB)

<a id='projectstructure'></a>

## Project Structure

This project is broken down into three main notebooks:

**Notebook 1: Data_Discovery**
* Load the General Population Demographics data
* Explore the existing data features and perform pre-processing
* Perform data cleanup and feature transformation
* Load and process additional datasets (Customer Demographics and Mailout Response)

**Notebook 2: Customer_Segmentation**

* Load General Population Demographics data and train a PCA transformer
* Apply PCA transformation to Customer Demographics data
* Explore PCA components composition
* Train k-Means and cluster General Population Demographics Data
* Explore clusters centroids composition
* Cluster Customer Demographics data 
* Compare General Population and Customers clusters composition

**Notebook 3: Mailout_Response_Prediction**

* Load Mailout train and test datasets
* Split train data into train and validation sets
* Define a series of binary classification models
* Train and deploy the models using SageMaker
* Evaluate classifiers using validation set
* Generate predictions for test set for Kaggle submission

In addition to the notebooks, some custom modules were created to simplify the operations:
* `processing`: contains helper routines to perform encoding and data transformation 
* `utils`: contains routines to access S3 resources and serialize/unserialize data
* `eda`: contains helper routines to access data quality and to compute and visualize features correlations


<a id='setup'></a>

## Setup Instructions

The notebooks provided in this repository are intended to be executed using Amazon's SageMaker platform. The following is a brief set of instructions on setting up a managed notebook instance using SageMaker, from which the notebooks can be completed and run.

### Log in to the AWS console and create a notebook instance

Log in to the [AWS console](https://console.aws.amazon.com) and go to the SageMaker dashboard. Click on 'Create notebook instance'.
* The notebook name can be anything and using ml.t2.2xlarge is a good idea since some processing steps are memory hungry
* For the role, creating a new role works fine. Using the default options is also okay. 
* It's important to note that you need the notebook instance to have access to S3 resources, which it does by default. In particular, any S3 bucket or object, with â€œsagemaker" in the name, is available to the notebook.
* Use the option to **git clone** the project repository into the notebook instance by pasting `https://github.com/rafaeldias-ml/nd009t-capstone.git`

#### Dependencies
In addition to most common packages available on SageMaker environments, the following packages are required to be manually installed:
- pyarrow
- category_encoders
- klib

### Open and run the notebook of your choice

Now that the repository has been cloned into the notebook instance you may navigate to any of the notebooks that you wish to complete or execute and work with them. Additional instructions are contained in their respective notebooks.

***
<a id='dataset'></a>

## Datasets

This project uses demographic data from general Germany population, from Arvato's costumers and from targets of a marketing campaign in order to draw strategies  for customer acquisition.

Due to sensitive and proprietary nature of data (although anonymized), the data is not publicly available but restricted to Udacity student's that sign off to terms of usage. Due to this restriction, the dataset will not be provided  as part of this project and a link for [terms of usage](https://classroom.udacity.com/nanodegrees/nd009t/parts/2f120d8a-e90a-4bc0-9f4e-43c71c504879/modules/7e69b87a-bf80-428e-89bf-358b2721fc16/lessons/4f0118c0-20fc-482a-81d6-b27507355985/concepts/bea4372b-5c40-4030-b324-9b2c291e55ae) will be provided instead.

Please note that this link is restricted to Nanodegree students.

For second task (Customer Segmentation Report) the following datasets with demographics data shall be used
-   `Udacity_AZDIAS_052018.csv`, with data from general population of Germany
	-  	891 211 persons (rows) x 366 features (columns).
-   `Udacity_CUSTOMERS_052018.csv`, with data from mail-order customers of a mail-order company
	- 191 652 persons (rows) x 369 features (columns).

For the third task, (Mail-order Response Prediction) the following datasets with demographics data for targets of a marketing campaign shall be used:
-   `Udacity_MAILOUT_052018_TRAIN.csv`: 42 982 persons (rows) x 367 (columns).
-   `Udacity_MAILOUT_052018_TEST.csv`:  42 833 persons (rows) x 366 (columns).

***
<a id='results'></a>

## Results

Please check Medium [post](https://capixaba.medium.com/customer-segmentation-for-bertelsmann-arvato-financial-services-c0b85e65bf7e) for a detailed report.

***
<a id='references'></a>

## References

Some usefull references for this project:
- https://docs.aws.amazon.com/sagemaker/latest/dg/how-pca-works.html
- https://aws.amazon.com/blogs/machine-learning/running-principal-component-analysis-in-amazon-sagemaker/
- https://aws.amazon.com/blogs/machine-learning/k-means-clustering-with-amazon-sagemaker/
- https://github.com/aws/amazon-sagemaker-examples/blob/master/introduction_to_applying_machine_learning/US-census_population_segmentation_PCA_Kmeans/sagemaker-countycensusclustering.ipynb
- https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html
- https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html
- https://en.wikipedia.org/wiki/Cram%C3%A9r's_V
- https://towardsdatascience.com/speed-up-your-data-cleaning-and-preprocessing-with-klib-97191d320f80
- https://towardsdatascience.com/xgboost-in-amazon-sagemaker-28e5e354dbcd

***
<a id='acknowledges'></a>

## Acknowledges

I would like to thank Arvato Financial Solutions for the data availability which made this project be possible.


